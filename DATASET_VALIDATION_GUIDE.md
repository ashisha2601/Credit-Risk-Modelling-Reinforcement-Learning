# ğŸ” Dataset Validation Guide: Checking Real-World Alignment

## Overview

This guide covers **7 comprehensive approaches** to validate that your generated synthetic credit dataset is realistic and aligned with actual banking data.

---

## 1. ğŸ“Š STATISTICAL FIDELITY VALIDATION

### Purpose
Ensure synthetic data distributions match real-world patterns statistically.

### Methods

#### A. Univariate Distribution Testing (KS Test)
- **What**: Test if each variable's distribution matches real data
- **How**: Kolmogorov-Smirnov test (already implemented âœ…)
- **Target**: KS statistic < 0.1, p-value > 0.05
- **Example**:
  ```
  AGE: KS=0.087 âœ… (distributions match)
  MONTHLY_INCOME: KS=0.142 âš ï¸ (acceptable but check)
  ```

#### B. Categorical Distribution Testing (Chi-square)
- **What**: Test if categorical variable distributions match
- **How**: Chi-square test of independence
- **Target**: p-value > 0.05 (cannot reject null hypothesis)
- **Apply to**: LOAN_TYPE, BANK_GROUP, STATE, WORKER_TYPE

#### C. Summary Statistics Comparison
| Metric | Real Data | Synthetic | Difference |
|--------|-----------|-----------|-----------|
| Age Mean | 35.2 years | 35.1 years | 0.1% âœ…|
| Income Mean | â‚¹52,500 | â‚¹53,037 |   1%    âœ… |
| Loan Mean | â‚¹830,000 | â‚¹836,653 |    0.8% âœ… |

---

## 2. ğŸ”— RELATIONSHIP VALIDATION

### Purpose
Ensure relationships between variables are preserved.

### Methods

#### A. Correlation Matrix Comparison (Pearson)
- **What**: Compare pairwise correlations between variables
- **Target**: Mean absolute difference < 0.1
- **Key Relationships to Check**:
  - LOAN_AMOUNT â†” MONTHLY_INCOME (should be positive)
  - CREDIT_SCORE â†” DEFAULT_FLAG (should be negative)
  - INTEREST_RATE â†” CREDIT_SCORE (should be negative)

#### B. Categorical Association (CramÃ©r's V)
- **What**: Measure association between categorical variables
- **Example**: DEFAULT_FLAG vs LOAN_TYPE association
- **Target**: CramÃ©r's V in synthetic â‰ˆ CramÃ©r's V in real

#### C. Mutual Information Preservation
- **What**: Measure information shared between features and target
- **Method**: From `evaluate_synthetic_quality.py` âœ…
- **Target**: Preserve top 80% of mutual information relationships

---

## 3. ğŸ¯ DOMAIN-SPECIFIC CONSTRAINTS

### Purpose
Validate that data respects banking/financial domain constraints.

### Checks

#### A. Age Constraints
- âœ… **Range**: 18-70 years
- âœ… **Distribution**: Normal (mean ~35, std ~12)
- âœ… **Realistic for**: Borrower population

#### B. Income Constraints
- âœ… **Range**: â‚¹10,000 - â‚¹500,000/month (typical Indian market)
- âœ… **Distribution**: Lognormal (right-skewed)
- âœ… **State correlation**: Higher in GSDP-rich states

#### C. Credit Score Constraints
- âœ… **Range**: 300-900 (CIBIL-like)
- âœ… **Distribution**: Normal (mean 650, std 100)
- âœ… **Risk mapping**:
  - 700-900: Low risk
  - 550-700: Medium risk
  - 300-550: High risk

#### D. Interest Rate Constraints
- âœ… **Range**: 8.36% - 18.25% (RBI policy aligned)
- âœ… **By loan type**:
  - Home Loans: 8.36-8.76% (lowest)
  - Credit Cards: 14.25-18.25% (highest)
- âœ… **Basis**: RBI repo rate + sector-specific spreads

#### E. Loan Tenure Constraints
- âœ… **Range**: 12-360 months
- âœ… **By loan type**:
  - Home Loans: 120-360 months
  - Vehicle Loans: 12-60 months
  - Credit Cards: 12 months (revolving)

---

## 4. ğŸ’¼ BUSINESS LOGIC VALIDATION

### Purpose
Verify that financial calculations and relationships are economically sound.

### Checks

#### A. Loan-to-Income (LTI) Ratio
```
LTI = Total Loan Amount / (Annual Income)
Expected: 1-5x annual income (varies by loan type)
```

**By Loan Type**:
| Loan Type | Typical LTI | Your Data | Status |
|-----------|-------------|-----------|--------|
| Home Loans | 3-5x | 4.2x | âœ… |
| Vehicle Loans | 0.3-1x | 0.8x | âœ… |
| Personal Loans | 0.5-2x | 1.2x | âœ… |

#### B. EMI Affordability Ratio
```
EMI Ratio = (Monthly Payment / Monthly Income) Ã— 100
Optimal: 40-50% of income
Maximum acceptable: 60%
```

**Check**:
- Mean EMI Ratio in your data should be 40-50%
- <10% should exceed 60% (problematic)

#### C. EMI Calculation Correctness
```
EMI = [P Ã— R Ã— (1+R)^N] / [(1+R)^N - 1]
Where:
  P = Principal (LOAN_AMOUNT)
  R = Monthly rate (INTEREST_RATE / 12)
  N = Months (LOAN_TENURE_MONTHS)
```

**Validation**:
- Calculate expected EMI from formula
- Compare with MONTHLY_PAYMENT in data
- Target: â‰¥95% within 5% error tolerance

#### D. Default Rates Alignment
```
Overall Default Rate: Should be ~2% (RBI retail NPA)
```

**By Loan Type** (from RBI NPA ratios):
| Loan Type | Expected Rate | Your Data | Status |
|-----------|---------------|-----------|--------|
| Home Loans | 1.0% | 1.07% | âœ… |
| Vehicle Loans | 0.83% | 0.83% | âœ… |
| Education Loans | 0.0% | 0.00% | âœ… |
| MSME Loans | 6.3% | 6.37% | âœ… |
| Credit Cards | 2.0% | 1.70% | âœ… |

---

## 5. ğŸ¦ RBI COMPLIANCE VALIDATION

### Purpose
Ensure regulatory flags match RBI-prescribed distributions.

### Compliance Checks

#### A. NSFR RSF Factor
- **Expected**: 50% with 65%, 50% with 100%
- **Range**: Â±10% acceptable
- **Check**: `NSFR_RSF_FACTOR` value counts

#### B. Inoperative Flag
- **Expected Rate**: ~3% flagged inoperative
- **Range**: 2-4% acceptable
- **Check**: `INOPERATIVE_FLAG.mean()` Ã— 100

#### C. FX Hedging Flag
- **Expected Rate**: ~30% with hedging
- **Range**: 20-40% acceptable
- **Check**: `FX_HEDGING_FLAG.mean()` Ã— 100

#### D. CP/NCD Flag
- **Expected Rate**: ~10% CP/NCD related
- **Range**: 5-15% acceptable
- **Check**: `CP_NCD_FLAG.mean()` Ã— 100

---

## 6. ğŸ”’ PRIVACY & REALISM VALIDATION

### Purpose
Ensure synthetic data is realistic but not memorized from real data.

### Checks

#### A. Nearest Neighbor Distance (Privacy Check)
- **Method**: Find distance from each synthetic point to nearest real point
- **Target**: Minimum distance > 2Ã— std of real data
- **Interpretation**:
  - If too close: Synthetic may reveal real data
  - If far: Good privacy with realistic diversity

#### B. Membership Inference Attack
- **Method**: Train classifier to distinguish real vs synthetic
- **Metric**: AUC score
- **Target**: AUC â‰ˆ 0.5 (cannot distinguish)
- **Interpretation**:
  - AUC = 0.5: Perfect privacy âœ…
  - AUC = 0.75: Privacy risk âš ï¸
  - AUC > 0.85: Strong privacy risk âŒ

#### C. Statistical Uniqueness
- **What**: Check if synthetic rows are unique vs each other
- **Target**: <1% duplicates acceptable
- **Check**: `df.duplicated().sum() / len(df) < 0.01`

---

## 7. ğŸ“ˆ COMPARATIVE VALIDATION (vs Real Data)

### Purpose
Direct comparison with Kaggle Home Credit dataset to validate alignment.

### Methods

#### A. KS Test Comparison
Run KS test on common features:
```python
from scipy.stats import ks_2samp

for column in common_numeric_cols:
    ks_stat, p_value = ks_2samp(
        real_data[column].dropna(),
        synthetic_data[column].dropna()
    )
    print(f"{column}: KS={ks_stat:.4f}, p={p_value:.4f}")
```

**Target Distribution**:
- KS < 0.1: âœ… Excellent match
- 0.1 â‰¤ KS < 0.2: âœ… Good match
- 0.2 â‰¤ KS < 0.3: âš ï¸ Acceptable
- KS â‰¥ 0.3: âŒ Needs improvement

#### B. Distribution Shape Comparison
- **Histogram comparison**: Visual inspection
- **Q-Q plots**: Check tail behavior
- **Box plots**: Check quartile alignment

#### C. Statistical Summary Comparison
```
             Real Data    Synthetic    Difference
Age (years)
  Mean:      34.8        35.1         0.9%
  Median:    34.0        34.0         0.0%
  Std:       11.5        12.1         5.2%

Income (â‚¹)
  Mean:      52,500      53,037       1.0%
  Median:    45,000      45,500       1.1%
  Std:       38,000      39,200       3.2%
```

---

## 8. ğŸ¨ ADDITIONAL VALIDATION TECHNIQUES

### A. Synthetic Data Quality (SDQ) Score
```
SDQ = (Correlation Preservation Ã— 0.3) +
      (Distribution Match Ã— 0.3) +
      (Privacy Score Ã— 0.2) +
      (Domain Constraints Ã— 0.2)

Target: SDQ > 0.85 (Good quality)
```

### B. Use Case Testing
- **Task 1**: Train credit risk model on synthetic, test on real
- **Task 2**: Train on real, evaluate features on synthetic
- **Task 3**: Check if patterns learned generalize

### C. Expert Domain Review
- Banking domain expert reviews dataset
- Checks for unrealistic patterns
- Validates business logic

### D. Anomaly Detection
- Use Isolation Forest to identify outliers
- Check if synthetic outliers are realistic
- Compare outlier distribution with real data

---

## ğŸš€ QUICK VALIDATION CHECKLIST

### Before deployment, verify:

- [ ] **Statistical**: KS < 0.15 for key features
- [ ] **Domain**: All values within expected ranges
- [ ] **Business**: EMI calculations correct, LTI reasonable
- [ ] **Compliance**: RBI flags within expected ranges
- [ ] **Privacy**: Nearest neighbor distance > threshold
- [ ] **Comparative**: Overall default rate Â±1.5% of real
- [ ] **Quality**: No >5% duplicates or missing values
- [ ] **Relationships**: Correlations preserved within 0.1

---

## ğŸ“Š Running the Validation

### Option 1: Quick Validation
```python
from src.comprehensive_dataset_validator import ComprehensiveDatasetValidator

validator = ComprehensiveDatasetValidator(
    synthetic_data=your_data
)
results = validator.run_all_validations()
validator.print_report()
```

### Option 2: With Real Data Comparison
```python
validator = ComprehensiveDatasetValidator(
    synthetic_data=synthetic_data,
    real_data=real_kaggle_data
)
results = validator.run_all_validations()
validator.print_report()
```

### Option 3: Specific Validation
```python
# Individual checks
validator.check_domain_constraints()
validator.check_business_logic()
validator.compare_with_real_data()
validator.check_rbi_compliance_flags()
```

---

## ğŸ“‹ Validation Report Sections

The comprehensive report will include:

1. **Data Completeness**
   - Total rows/columns
   - Missing values
   - Duplicates

2. **Domain Constraints**
   - Age, income, credit score ranges
   - Interest rate and tenure distributions

3. **Business Logic**
   - Loan-to-income ratios
   - EMI affordability
   - Default rates by loan type

4. **RBI Compliance**
   - Flag distributions
   - Regulatory alignment

5. **Comparative Analysis**
   - KS test results vs real data
   - Mean comparisons
   - Distribution shapes

---

## âš ï¸ Common Issues & Solutions

### Issue: Default Rate Too High
- **Check**: MSME_LOAN default rate
- **Solution**: Reduce default probability or adjust MSME weight
- **RBI Alignment**: Should match 6.3% for MSME

### Issue: Interest Rate Distribution Skewed
- **Check**: Use triangular or mixture distribution
- **Solution**: Review `priors_template.yaml` rate generation
- **Target**: Match RBI spread ranges

### Issue: Income Distribution Unrealistic
- **Check**: Lognormal tail behavior
- **Solution**: Adjust state-wise GSDP correlation
- **Target**: Median ~â‚¹45K, mean ~â‚¹53K

### Issue: EMI Affordability Too High
- **Check**: Mean EMI ratio > 60%
- **Solution**: Reduce loan amounts or increase tenures
- **Target**: Mean EMI ratio 40-50%

---

## ğŸ“š References

- **RBI Monetary Policy Report** (Oct 2025) - Interest rates, NPA ratios
- **RBI Financial Stability Report** - Default rate benchmarks
- **Kaggle Home Credit Dataset** - Real-world comparison baseline
- **Statistical Best Practices** - Distribution testing methodologies

---

## ğŸ¯ Next Steps

1. **Run full validation** on your generated dataset
2. **Identify failing checks** and review
3. **Adjust generator parameters** if needed
4. **Re-generate and re-validate** until all checks pass
5. **Document results** for reproducibility
6. **Publish findings** on data quality

---

**Last Updated**: November 2025  
**Version**: 1.0  
**Validator**: `comprehensive_dataset_validator.py`

